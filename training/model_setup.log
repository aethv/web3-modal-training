2025-04-16 17:53:36,986 - __main__ - INFO - Initializing Web3ModelSetup
2025-04-16 17:53:36,987 - __main__ - INFO - Using device: cpu
2025-04-16 17:53:36,987 - __main__ - INFO - Downloading base model: codellama/CodeLlama-7b-hf
2025-04-16 17:54:01,146 - __main__ - INFO - Base model and tokenizer downloaded successfully
2025-04-16 17:57:09,613 - __main__ - INFO - Model and tokenizer saved to ./models/base_model
2025-04-16 17:57:09,625 - __main__ - INFO - Preparing initial dataset
2025-04-16 17:57:09,626 - __main__ - INFO - Building dataset from web3 code samples
2025-04-16 17:57:09,700 - __main__ - INFO - Dataset saved to ./data/initial_dataset
2025-04-16 17:57:09,700 - __main__ - INFO - Tokenizing dataset
2025-04-16 17:57:09,716 - __main__ - ERROR - Error tokenizing dataset: name 'tokenizer' is not defined
2025-04-16 17:57:09,716 - __main__ - INFO - Setting up training arguments
2025-04-16 17:57:09,770 - __main__ - INFO - Training arguments saved to ./outputs/training_args.json
2025-04-16 17:57:09,770 - __main__ - INFO - All setup steps complete. Ready for training!
2025-04-16 17:57:09,770 - __main__ - INFO - Setup ready for training: True
2025-04-16 18:02:32,942 - __main__ - INFO - Initializing Web3ModelSetup
2025-04-16 18:02:32,942 - __main__ - INFO - Using device: cpu
2025-04-16 18:02:32,942 - __main__ - INFO - Downloading base model: codellama/CodeLlama-7b-hf
2025-04-16 18:02:58,657 - __main__ - INFO - Base model and tokenizer downloaded successfully
2025-04-16 18:05:46,876 - __main__ - INFO - Model and tokenizer saved to ./models/base_model
2025-04-16 18:05:46,916 - __main__ - INFO - Preparing initial dataset
2025-04-16 18:05:46,916 - __main__ - INFO - Building dataset from web3 code samples
2025-04-16 18:05:47,879 - __main__ - INFO - Dataset saved to ./data/initial_dataset
2025-04-16 18:05:47,879 - __main__ - INFO - Tokenizing dataset
2025-04-16 18:05:48,470 - __main__ - INFO - Setting up training arguments
2025-04-16 18:05:48,839 - __main__ - INFO - Training arguments saved to ./outputs/training_args.json
2025-04-16 18:05:48,839 - __main__ - INFO - All setup steps complete. Ready for training!
2025-04-16 18:05:48,839 - __main__ - INFO - Setup ready for training: True
2025-04-16 18:09:11,656 - __main__ - INFO - Initializing Web3ModelSetup
2025-04-16 18:09:11,657 - __main__ - INFO - Using device: cpu
2025-04-16 18:09:11,657 - __main__ - INFO - Downloading base model: codellama/CodeLlama-7b-hf
2025-04-16 18:09:39,867 - __main__ - INFO - Base model and tokenizer downloaded successfully
2025-04-16 18:13:33,071 - __main__ - INFO - Model and tokenizer saved to ./models/base_model
2025-04-16 18:13:33,078 - __main__ - INFO - Preparing initial dataset
2025-04-16 18:13:33,078 - __main__ - INFO - Building dataset from web3 code samples
2025-04-16 18:13:33,208 - __main__ - INFO - Dataset saved to ./data/initial_dataset
2025-04-16 18:13:33,208 - __main__ - INFO - Tokenizing dataset
2025-04-16 18:13:33,354 - __main__ - INFO - Setting up training arguments
2025-04-16 18:13:33,410 - __main__ - INFO - Training arguments saved to ./outputs/training_args.json
2025-04-16 18:13:33,410 - __main__ - INFO - All setup steps complete. Ready for training!
2025-04-16 18:13:33,410 - __main__ - INFO - Setup ready for training: True
